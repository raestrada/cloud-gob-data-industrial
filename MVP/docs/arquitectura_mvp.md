# Arquitectura del MVP de IA para FinOps

**Proyecto:** Migraci√≥n Industrial a Google Cloud Platform
**Fecha:** 2025-11-01
**Versi√≥n:** 1.0

## Resumen Ejecutivo

Este MVP demuestra la viabilidad t√©cnica y valor de negocio de aplicar IA/ML a FinOps en GCP, implementando tres casos de uso cr√≠ticos mediante una arquitectura **event-driven desde el d√≠a 1**, eliminando completamente la deuda t√©cnica.

### Principio Arquitect√≥nico Clave

> **El MVP consume eventos desde el inicio, aunque sean simulados.**
>
> Esto permite prototipado r√°pido sin generar deuda t√©cnica, porque el c√≥digo del MVP **ES** el c√≥digo de producci√≥n.

---

## 1. Stack Tecnol√≥gico del MVP

| Componente | Tecnolog√≠a | Prop√≥sito |
|:---|:---|:---|
| **Lenguaje** | Python 3.9+ | Desarrollo de notebooks y scripts |
| **Package Manager** | `uv` | Gesti√≥n ultra-r√°pida de deps y venvs |
| **Notebooks** | Jupyter | An√°lisis interactivo y documentaci√≥n |
| **ML Libraries** | scikit-learn, XGBoost | Modelos de forecast, anomal√≠as, NLP |
| **Data Processing** | Pandas, NumPy | Manipulaci√≥n de eventos y features |
| **Visualizaci√≥n** | Matplotlib, Seaborn | Gr√°ficos y dashboards |
| **Event Format** | JSONL (JSON Lines) | Simulaci√≥n de mensajes Kafka |
| **Datos** | Archivos locales | Eventos sint√©ticos en `data/` |

**Simplicidad intencional:** No se requiere Kafka, BigQuery, ni GCP durante el MVP. Todo corre localmente.

**Velocidad:** Usando `uv` en lugar de pip tradicional (10-100x m√°s r√°pido para instalar dependencias).

---

## 2. Arquitectura de Datos: Event-First

### 2.1 Formato de Eventos

Todos los datos se estructuran como **eventos JSONL**, simulando exactamente el formato que producir√° Kafka en producci√≥n.

#### Evento de Billing (`billing.cost.monthly`)

```json
{
  "timestamp": "2025-01-01T00:00:00Z",
  "period": "monthly",
  "month": "M1",
  "project_id": "prod-industrial-fleet",
  "service": "compute",
  "sku": "n2-standard-fleet",
  "cost_usd": 95000.0,
  "usage_amount": 684000.0,
  "usage_unit": "vCPU-hours",
  "production_units": 130000,
  "labels": {
    "env": "prod",
    "business_unit": "industrial-operations",
    "cost_center": "CC-1000"
  }
}
```

#### Evento de Producci√≥n (`production.metrics.monthly`)

```json
{
  "timestamp": "2025-01-01T00:00:00Z",
  "period": "monthly",
  "month": "M1",
  "production_units": 130000,
  "total_cost_usd": 218300.0,
  "cost_per_unit": 1.6792,
  "labels": {
    "business_unit": "industrial-operations"
  }
}
```

### 2.2 Mapeo CSV ‚Üí Eventos

El CSV hist√≥rico (12 filas) se transforma en eventos manteniendo:
- **Misma granularidad** (mensual)
- **Mismos valores** (diferencia $0.00)
- **Formato Kafka-compatible**

**Resultado:**
- 60 eventos de billing (12 meses √ó 5 servicios)
- 12 eventos de producci√≥n (12 meses)
- **Total: 72 eventos** vs 12 filas CSV

---

## 3. Arquitectura de los 3 Casos de Uso

### 3.1 Forecast de Costos

```mermaid
flowchart TB
    subgraph input["üì• INPUT"]
        JSONL[kafka_events_billing.jsonl<br/>72 eventos mensuales]
    end

    subgraph pipeline["üîÑ FORECAST PIPELINE"]
        Consumer[Event Consumer<br/>read_billing_events]
        FE[Feature Engineering<br/>cost_lag_1, cost_lag_2<br/>cost_ma_3, z_score]
        Train[ML Models Training<br/>Linear Regression<br/>Random Forest<br/>XGBoost]
        Select[Model Selection<br/>max accuracy ‚â•90%]
        Forecast[Forecast M13-M15<br/>Predicci√≥n 3 meses]
        Alert[Alertas Tempranas<br/>Si forecast > budget]
    end

    subgraph output["üì§ OUTPUT"]
        Results[Forecast + Alerts<br/>Accuracy ‚â•90%]
    end

    JSONL --> Consumer
    Consumer --> FE
    FE --> Train
    Train --> Select
    Select --> Forecast
    Forecast --> Alert
    Alert --> Results

    style input fill:#e3f2fd
    style pipeline fill:#f3e5f5
    style output fill:#e8f5e9
    style Select fill:#fff59d
```

**M√©tricas objetivo:**
- Accuracy ‚â•90%
- Alertas 15 d√≠as antes del cierre
- Ahorro: $50-100K/a√±o

### 3.2 Detecci√≥n de Anomal√≠as

```mermaid
flowchart TB
    subgraph input["üì• INPUT"]
        Events[kafka_events_billing.jsonl<br/>+ Anomal√≠as sint√©ticas 10%]
    end

    subgraph pipeline["üö® ANOMALY DETECTION PIPELINE"]
        Stream[Event Stream<br/>Consumir eventos]
        Features[Feature Calculation<br/>Z-score por servicio<br/>Ratio vs promedio<br/>Costo absoluto]
        IsoForest[Isolation Forest<br/>contamination=10%<br/>unsupervised]
        Detect[Anomaly Detection<br/>prediction == -1<br/>+ anomaly_score]
        Severity[Severity Assessment<br/>ALTA: z_score > 5<br/>MEDIA: z_score ‚â§ 5]
        Alert[Alert Generation<br/>Slack / Email / Jira<br/><2 horas]
    end

    subgraph output["üì§ OUTPUT"]
        Results[Alertas + Tickets<br/>F1-score ‚â•85%]
    end

    Events --> Stream
    Stream --> Features
    Features --> IsoForest
    IsoForest --> Detect
    Detect --> Severity
    Severity --> Alert
    Alert --> Results

    style input fill:#e3f2fd
    style pipeline fill:#ffebee
    style output fill:#e8f5e9
    style Alert fill:#ff5252,color:#fff
```

**M√©tricas objetivo:**
- F1-score ‚â•85%
- Detecci√≥n <2 horas
- Ahorro: $30-50K/a√±o

### 3.3 NLP Etiquetado Autom√°tico

```mermaid
flowchart TB
    subgraph input["üì• INPUT"]
        Unlabeled[kafka_events_billing.jsonl<br/>Recursos sin etiquetas ~20%]
    end

    subgraph pipeline["üè∑Ô∏è AUTO-LABELING PIPELINE NLP"]
        Filter[Filter Unlabeled<br/>labels == {}]
        TextFeat[Text Features<br/>resource_name + project_id<br/>+ service + sku]
        TFIDF[TF-IDF Vectorizer<br/>max_features=100<br/>ngram_range 1-2]
        Classifiers[Multi-Label Classifiers<br/>owner_clf<br/>cost_center_clf<br/>plant_clf]
        Confidence[Confidence Calculation<br/>avg de 3 predicciones]
        Decision{Confidence<br/>‚â•75%?}
        AutoLabel[Auto-Label<br/>Aplicar etiquetas]
        Manual[Manual Review<br/>Queue para humano]
    end

    subgraph output["üì§ OUTPUT"]
        Results[Label Compliance<br/>80% ‚Üí 95%+]
    end

    Unlabeled --> Filter
    Filter --> TextFeat
    TextFeat --> TFIDF
    TFIDF --> Classifiers
    Classifiers --> Confidence
    Confidence --> Decision
    Decision -->|S√≠| AutoLabel
    Decision -->|No| Manual
    AutoLabel --> Results
    Manual --> Results

    style input fill:#e3f2fd
    style pipeline fill:#fff3e0
    style output fill:#e8f5e9
    style Decision fill:#fff59d
    style AutoLabel fill:#4caf50,color:#fff
    style Manual fill:#ff9800,color:#fff
```

**M√©tricas objetivo:**
- Label compliance ‚â•95%
- Accuracy ‚â•90%
- Ahorro: $15-20K/a√±o

---

## 4. Flujo de Ejecuci√≥n del MVP

### 4.1 Setup Inicial

**Con `uv` (Recomendado - 10-100x m√°s r√°pido):**

```bash
# Clonar repositorio
git clone <repo-url>
cd MVP

# Instalar uv (si no lo tienes)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Crear venv + instalar dependencias (¬°solo 304 ms!)
uv venv
uv pip install pandas numpy scikit-learn xgboost matplotlib seaborn jupyter ipykernel notebook

# Generar eventos desde CSV
source .venv/bin/activate
cd data
python generate_events.py
```

**Con pip tradicional:**

```bash
# Clonar repositorio
git clone <repo-url>
cd MVP

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate

# Instalar dependencias
pip install -e .

# Generar eventos desde CSV
cd data
python generate_events.py
```

**Output:**
```
‚úÖ Generados 60 eventos de billing
‚úÖ Generados 12 eventos de producci√≥n
üìä Total: 72 eventos
‚ú® Diferencia vs CSV: $0.00
```

### 4.2 Ejecuci√≥n de Notebooks

**Orden de ejecuci√≥n:**

1. **`00_data_generation.ipynb`**
   - Documenta el enfoque Event-First
   - Valida que eventos == CSV
   - Explora distribuci√≥n de datos

2. **`01_forecast_costos.ipynb`**
   - Entrena modelos de forecast
   - Selecciona mejor modelo (accuracy ‚â•90%)
   - Genera forecast para M13-M15
   - Crea alertas tempranas

3. **`02_deteccion_anomalias.ipynb`**
   - Inyecta anomal√≠as sint√©ticas (10%)
   - Entrena Isolation Forest
   - Valida F1-score ‚â•85%
   - Simula flujo de alertas

4. **`03_nlp_etiquetado.ipynb`**
   - Entrena 3 clasificadores NLP
   - Auto-etiqueta recursos hu√©rfanos
   - Calcula nuevo compliance (‚â•95%)
   - Estima ahorro financiero

---

## 5. C√≥digo Reutilizable: MVP ‚Üí Producci√≥n

### 5.1 Event Consumer (Gen√©rico)

**MVP:**
```python
def read_billing_events(filepath):
    events = []
    with open(filepath, 'r') as f:
        for line in f:
            events.append(json.loads(line))
    return events

events = read_billing_events('../data/kafka_events_billing.jsonl')
```

**Producci√≥n** (solo cambiar esta funci√≥n):
```python
from kafka import KafkaConsumer

def read_billing_events(topic='billing.cost.monthly'):
    consumer = KafkaConsumer(
        topic,
        bootstrap_servers=['kafka-hub.gcp.internal:9092'],
        value_deserializer=lambda m: json.loads(m.decode('utf-8'))
    )
    events = [msg.value for msg in consumer]
    return events

events = read_billing_events()  # ‚Üê MISMO c√≥digo despu√©s
```

### 5.2 Feature Engineering (Id√©ntico)

```python
# Este c√≥digo NO cambia entre MVP y producci√≥n
df = pd.DataFrame(events)
df['z_score'] = (df['cost_usd'] - df['service_mean']) / df['service_std']
df['cost_ratio'] = df['cost_usd'] / df['service_mean']
```

### 5.3 ML Pipeline (Id√©ntico)

```python
# Este c√≥digo NO cambia entre MVP y producci√≥n
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)
predictions = model.predict(X_test)
```

**Clave:** Solo cambia la **fuente de eventos**, no el pipeline de ML.

---

## 6. Validaci√≥n de Objetivos del MVP

| Objetivo | Meta | M√©todo de Validaci√≥n | Notebook |
|:---|:---|:---|:---|
| **Forecast Accuracy** | ‚â•90% | MAPE en test set (M10-M12) | `01_forecast_costos.ipynb` |
| **Anomaly F1-Score** | ‚â•85% | F1 con anomal√≠as sint√©ticas | `02_deteccion_anomalias.ipynb` |
| **Label Compliance** | ‚â•95% | % recursos etiquetados post-ML | `03_nlp_etiquetado.ipynb` |
| **Event Parity** | $0 diff | Total eventos vs CSV | `00_data_generation.ipynb` |

---

## 7. Limitaciones del MVP (Intencionales)

### 7.1 Datos Sint√©ticos

- **MVP:** Eventos generados desde CSV hist√≥rico
- **Producci√≥n:** Eventos reales desde Kafka

**Impacto:** Ninguno. El pipeline es id√©ntico.

### 7.2 Entrenamiento Local

- **MVP:** Modelos entrenados en Jupyter local
- **Producci√≥n:** Vertex AI AutoML + retraining autom√°tico

**Impacto:** Modelos del MVP sirven como baseline. Vertex AI mejorar√° accuracy.

### 7.3 Sin Persistencia

- **MVP:** Modelos en memoria durante ejecuci√≥n del notebook
- **Producci√≥n:** Modelos en Vertex AI Model Registry

**Impacto:** F√°cil migraci√≥n con `model.save()` ‚Üí Vertex AI.

### 7.4 Batch Processing

- **MVP:** Procesar todos los eventos de una vez
- **Producci√≥n:** Stream processing evento por evento

**Impacto:** C√≥digo ya est√° preparado (`detect_anomaly_realtime()` procesa 1 evento).

---

## 8. Requisitos del Entorno

### 8.1 Hardware M√≠nimo

- **CPU:** 2 cores
- **RAM:** 4 GB
- **Disco:** 1 GB libre

**Raz√≥n:** Procesamos solo 72 eventos, modelos peque√±os.

### 8.2 Software

**Instalaci√≥n r√°pida con `uv`:**
```bash
# Instalar uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Instalar dependencias
cd MVP
uv venv
uv pip install pandas numpy scikit-learn xgboost matplotlib seaborn jupyter ipykernel notebook
```

**Dependencias (definidas en `pyproject.toml`):**
- Python 3.9+
- pandas>=1.5.0
- numpy>=1.23.0
- scikit-learn>=1.2.0
- xgboost>=1.7.0
- matplotlib>=3.6.0
- seaborn>=0.12.0
- jupyter>=1.0.0

### 8.3 No se Requiere

- ‚ùå GCP Account
- ‚ùå Kafka instalado
- ‚ùå BigQuery
- ‚ùå Vertex AI
- ‚ùå Conectividad a internet (excepto para instalar deps)

**Ventaja:** El MVP corre 100% offline, ideal para demos y validaci√≥n.

---

## 9. Pr√≥ximos Pasos

Ver `arquitectura_productiva.md` para:
- Migraci√≥n a Kafka
- Integraci√≥n con Vertex AI
- Deployment en GKE
- Automatizaci√≥n con Cloud Scheduler

Ver `plan_implementacion.md` para:
- Plan 30-60-90 d√≠as
- Hitos y deliverables
- Estrategia de adopci√≥n
