# Proyecto: MigraciÃ³n y OperaciÃ³n en Google Cloud con Gobierno FinOps e IA

---

## âš ï¸ **IMPORTANTE: NATURALEZA DEL PROYECTO**

**ğŸ¯ ESTE ES UN EJERCICIO/DESAFÃO DE DISEÃ‘O ARQUITECTÃ“NICO**

Este proyecto es un caso de estudio educativo para diseÃ±ar una soluciÃ³n completa de migraciÃ³n cloud industrial con gobierno FinOps e IA. Por lo tanto:

âœ… **ESTÃ PERMITIDO Y NECESARIO usar SUPUESTOS**
- Los supuestos son necesarios para completar el diseÃ±o arquitectÃ³nico
- Deben ser **los mÃ­nimos indispensables** para resolver los entregables
- **OBLIGATORIO**: Marcar explÃ­citamente como **[SUPUESTO]** en los documentos
- **OBLIGATORIO**: Justificar cada supuesto con razonamiento tÃ©cnico/financiero

ğŸ“‹ **DISTINCIÃ“N CRÃTICA: Datos Reales vs Supuestos**
- **Datos Reales**: Provienen del PDF del caso de negocio en `docs/`
- **Supuestos**: Todo lo demÃ¡s (costos estimados, throughput, latencias, etc.)
- **Formato requerido**:
  - `[DATO VALIDADO - Caso de Negocio pÃ¡g. X]` para datos reales
  - `[SUPUESTO - justificaciÃ³n]` para estimaciones

ğŸ¯ **OBJETIVO DEL EJERCICIO**
- Completar los 5 entregables finales (PDFs) con rigor tÃ©cnico
- Demostrar capacidad de diseÃ±o arquitectÃ³nico distribuido
- Aplicar mejores prÃ¡cticas de FinOps, MLOps, GitOps, DevSecOps
- Ser **transparente** sobre quÃ© es dato vs estimaciÃ³n

---

## DescripciÃ³n del Proyecto

Caso de negocio para liderar la migraciÃ³n y operaciÃ³n de infraestructura industrial crÃ­tica hacia Google Cloud Platform (GCP) en un plazo de 12-18 meses, con un enfoque en resiliencia, RPO/RTO cercano a cero, arquitectura basada en eventos, y gobierno FinOps.

## Contexto del Negocio

### Alcance
- **Timeline**: 12-18 meses
- **Plantas**: Monterrey, Guadalajara, Tijuana + Corporativo
- **Cargas**: 420 VMs (~1,900 vCPU, ~12.8TB RAM)
- **Almacenamiento**: ~200TB block + ~500TB object (crecimiento 20% anual)
- **ProducciÃ³n anual**: 1,560,000 unidades
- **TCO on-prem (3 aÃ±os)**: USD 15,735,000
- **OPEX on-prem anual**: USD 5,245,000

### Sistemas CrÃ­ticos (RPO/RTO = 0)
- **SCADA antiguos**: 40 instancias (latencia ultra-baja requerida)
- **SQL Server 2019**: 120 instancias crÃ­ticas (plantas + corporativo)

### Restricciones TÃ©cnicas
- Interconnect 1Gbps ya operativo (Monterrey â†” GCP)
- Cloud VPN como respaldo
- Ventanas de mantenimiento: Domingos 2h por planta
- Freeze anual: 15-Nov al 5-Ene
- SLA objetivo: 99.95% global; 99.99% en crÃ­ticos
- Procedimientos almacenados que invocan .exe locales

## Arquitectura Propuesta

### Principios ArquitectÃ³nicos

1. **Edge-First Architecture**: Procesamiento local mÃ¡ximo en planta (offline-capable), cloud para agregaciÃ³n multi-planta
2. **Event-Driven Architecture (EDA)**: Todo debe escribirse como eventos
3. **RPO/RTO â‰ˆ 0 Local**: Resiliencia en edge, replicaciÃ³n asÃ­ncrona priorizada a cloud
4. **Stack Nativo GCP**: Google Distributed Cloud Edge (on-prem) + GKE (cloud) unificado
5. **Data Hub Distribuido**: Kafka Confluent con topologÃ­a arbitraria via Cluster Linking
6. **ReplicaciÃ³n Inteligente**: PriorizaciÃ³n por criticidad (alarmas â†’ alta, batch â†’ media, logs â†’ baja)
7. **Zero-Trust Nativo**: IAP + Identity Platform federado, sin IPs pÃºblicas (PSC + mTLS)
8. **Everything as Code**: GitOps con Anthos Config Management para toda la infraestructura

### Stack TecnolÃ³gico Principal

#### Plataforma de Eventos
- **Confluent Kafka** (managed service)
  - Cluster Linking para replicaciÃ³n multi-regiÃ³n sub-segundo
  - Kafka Connect con Debezium para CDC (Change Data Capture)
  - KSQL para stream processing
  - Tiered Storage para optimizaciÃ³n de costos
  - RazÃ³n: No usar MirrorMaker 2 debido a RPO/RTO=0 requerido
  - RazÃ³n: No usar Pub/Sub o Spanner (menor latencia, exactly-once, mejor integraciÃ³n legados)

#### OrquestaciÃ³n y Compute
- **Google Distributed Cloud Edge (GDC Edge)**:
  - GKE Edge en plantas (on-premise, offline-capable)
  - Anthos para gestiÃ³n unificada edge + cloud
  - Procesamiento local completo sin dependencia de conectividad
  - SincronizaciÃ³n asÃ­ncrona priorizada hacia GCP
- **GKE (Google Kubernetes Engine)**: Cloud workloads para analÃ­tica multi-planta
- **Dataproc on GKE (edge + cloud)**:
  - Spark/Flink managed desplegable en GKE cloud y GKE Edge
  - Procesamiento de ventanas temporales, batch, streaming
  - OptimizaciÃ³n automÃ¡tica de recursos Dataproc + Cast.ai
  - Despliegue homogÃ©neo edge â†” cloud con misma API
  - RazÃ³n: Dataproc managed vs Spark standalone (menor operaciÃ³n, auto-scaling)
  - RazÃ³n: Cast.ai optimiza dinÃ¡micamente los workers K8s de Dataproc (~40% ahorro)
- **Cast.ai**: OptimizaciÃ³n dinÃ¡mica predictiva de recursos K8s (GKE + Dataproc)
- **Anthos Service Mesh**: mTLS, observabilidad, traffic management edge â†” cloud
- RazÃ³n: GDC Edge permite resiliencia industrial real (operaciÃ³n local sin cloud)
- RazÃ³n: Stack 100% GCP nativo simplifica FinOps y operaciÃ³n
- RazÃ³n: Dataproc on GKE permite procesamiento edge + cloud unificado

#### Networking y Seguridad
- **Private Service Connect (PSC)**:
  - Conectividad privada edge â†” cloud sin IPs pÃºblicas
  - Sin overlap de redes IP entre plantas y cloud
  - ComunicaciÃ³n segura via endpoints privados
- **Anthos Service Mesh**:
  - mTLS automÃ¡tico para todo el trÃ¡fico (edge â†” cloud)
  - Control de trÃ¡fico L7 nativo (Traffic Director)
  - Observabilidad distribuida end-to-end
  - PolÃ­ticas de seguridad granulares
- **Identity-Aware Proxy (IAP)**:
  - Zero-Trust para accesos humanos
  - Sin VPN tradicional
  - FederaciÃ³n con Identity Platform (SAML/OIDC)
  - IntegraciÃ³n con AD corporativo/SSO
- **Interconnect 1Gbps**: Conectividad privada fÃ­sica Monterrey â†” GCP
- **Cloud VPN HA**: Respaldo redundante para Interconnect
- **GCP Shared VPC**: Hub-and-spoke para organizaciÃ³n multi-proyecto
- **VPC Service Controls**: PerÃ­metros de seguridad para datos sensibles
- **Secret Manager + KMS/CMEK**: Secretos y encriptaciÃ³n en trÃ¡nsito/reposo
- **RazÃ³n**: Stack 100% GCP nativo, sin dependencia multiproveedor
- **RazÃ³n**: Menor costo operativo, FinOps unificado, mismo proveedor

#### GitOps y CI/CD
- **Anthos Config Management**:
  - GitOps unificado para GDC Edge + GKE cloud
  - Policy Controller (OPA integrado)
  - Config Sync para despliegues declarativos
  - GestiÃ³n centralizada multi-cluster (edge + cloud)
- **Harness**:
  - Control de despliegues y CI/CD avanzado
  - Backstage como Internal Developer Portal (IDP)
  - Blue/Green y Canary deployments
  - Chaos Engineering para validaciÃ³n RPO/RTO
  - MÃ©tricas DORA y SPACE
  - FinOps predictivo integrado
- **Policy Controller (OPA nativo Anthos)**: Gobierno y compliance unificado
- **Terraform**: AutomatizaciÃ³n de infraestructura GCP
- **RazÃ³n**: Anthos unifica GitOps edge + cloud, elimina complejidad multi-plataforma

#### Data Platform
- **Arquitectura Medallion (extendida)**:
  - TÃ³pico RAW: Captura inicial via Kafka Connect (edge + cloud)
  - Procesamiento edge: KSQL (transformaciones ligeras, filtrado, priorizaciÃ³n)
  - Procesamiento cloud: Dataproc on GKE (agregaciones multi-planta, analÃ­tica compleja)
  - Capas adicionales: AnonimizaciÃ³n, limpieza, deduplicaciÃ³n, agregaciones
  - ProtecciÃ³n de BD transaccionales: Lectura una vez, consumo mÃºltiple
- **Google Cloud Storage**: Persistencia final (hot/cold/archive tiers)
- **BigQuery**: MPP para analytics multi-planta
- **Looker**: VisualizaciÃ³n y dashboards
- **Kafka Tiered Storage**: ReducciÃ³n de costos almacenamiento histÃ³rico
- **RazÃ³n**: KSQL edge (ligero) + Dataproc cloud (pesado) = procesamiento distribuido inteligente

#### MLOps y AI
- **Vertex.ai**: MLOps nativo GCP (edge + cloud)
- **Vertex AI Workbench**: Entorno unificado desarrollo edge â†” cloud
- **Cast.ai LLM/Data Cache**: ReducciÃ³n costos transferencia y LLM
- **LangFuse + LangChain**: FinOps para LLM
- **Principio**: Todo alimentado por eventos, modelos desplegables en edge para inferencia local

#### Observabilidad
- **Cloud Operations Suite (anteriormente Stackdriver)**:
  - Cloud Monitoring: MÃ©tricas edge + cloud unificadas
  - Cloud Logging: Logs centralizados desde GDC Edge
  - Cloud Trace: Tracing distribuido via Anthos Service Mesh
  - Cloud Profiler: Performance profiling
- **Anthos Service Mesh Observability**: TrÃ¡fico L7, latencias, errores edge â†” cloud
- **OpenTelemetry**: InstrumentaciÃ³n estÃ¡ndar para aplicaciones
- **RazÃ³n**: Stack 100% GCP nativo simplifica FinOps y operaciÃ³n vs multiproveedor

### Capas de Datos (Data Hub)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ EDGE (GKE Edge + Kafka) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Fuentes Legadas â†’ Kafka Connect/Debezium â†’ TÃ³pico RAW (edge)  â”‚
â”‚                                              â†“                  â”‚
â”‚                                    Procesamiento KSQL           â”‚
â”‚                                    (filtrado, priorizaciÃ³n)     â”‚
â”‚                                              â†“                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â†“
                          [Cluster Linking - Solo datos crÃ­ticos/agregados]
                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLOUD (GKE + Kafka) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                                    TÃ³pico RAW (cloud)           â”‚
â”‚                                              â†“                  â”‚
â”‚                              Procesamiento Dataproc on GKE     â”‚
â”‚                              (agregaciones multi-planta)       â”‚
â”‚                                              â†“                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚         â†“                      â†“                      â†“         â”‚â”‚
â”‚   AnonimizaciÃ³n           Limpieza            DeduplicaciÃ³n    â”‚â”‚
â”‚         â†“                      â†“                      â†“         â”‚â”‚
â”‚   Agregaciones          Enriquecimiento       ValidaciÃ³n       â”‚â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                              â†“                  â”‚
â”‚                                    TÃ³picos Procesados           â”‚
â”‚                                              â†“                  â”‚
â”‚                                    Google Cloud Storage         â”‚
â”‚                                    (hot/cold/archive)           â”‚
â”‚                                              â†“                  â”‚
â”‚                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                â†“                            â†“  â”‚
â”‚                            BigQuery                    Lakehouseâ”‚
â”‚                                â†“                            â†“  â”‚
â”‚                            Looker                      Vertex.aiâ”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ventajas Clave de la Arquitectura

1. **Resiliencia Industrial Real**: GDC Edge permite operaciÃ³n local sin dependencia de cloud
2. **RPO/RTO â‰ˆ 0 Local**: Procesamiento edge completo, replicaciÃ³n asÃ­ncrona priorizada
3. **Stack 100% GCP Nativo**: Menor costo operativo, FinOps unificado, un solo proveedor
4. **Zero-Trust Nativo**: IAP + mTLS sin multiproveedor
5. **ReplicaciÃ³n Inteligente**: PriorizaciÃ³n por criticidad (alarmas â†’ alta, batch â†’ baja)
6. **Datos Sensibles On-Prem**: Solo agregados suben a cloud, cumplimiento y privacidad
7. **RecuperaciÃ³n avanzada Kafka**: Offset replay, exactly-once semantics
8. **Orden garantizado**: Kafka mantiene orden en particiones (crÃ­tico para seÃ±ales industriales)
9. **TopologÃ­a arbitraria**: Cluster Linking permite cualquier topologÃ­a multi-regiÃ³n edge â†” cloud
10. **Sin Overlap IPs**: Private Service Connect + mTLS elimina conflictos de red
11. **GestiÃ³n Unificada**: Anthos Config Management para edge + cloud desde un solo control plane
12. **Procesamiento Distribuido Inteligente**: KSQL edge (ligero) + Dataproc on GKE cloud (pesado)
13. **Costos Optimizados**: Cast.ai optimiza GKE + Dataproc workers, Kafka Tiered Storage, polÃ­ticas OPA

## Razones para Decisiones ArquitectÃ³nicas

### Â¿Por quÃ© Confluent Kafka y no alternativas nativas de GCP?

1. **Pub/Sub**:
   - Mayor latencia que Cluster Linking
   - No garantiza exactly-once
   - Menor integraciÃ³n con BD legadas

2. **Spanner**:
   - No es plataforma de eventos
   - Mayor complejidad para streaming
   - Costos mÃ¡s altos

3. **Confluent Kafka**:
   - Latencia sub-segundo (Cluster Linking)
   - Exactly-once semantics
   - Kafka Connect + Debezium para sistemas legados (SCADA, SQL Server)
   - Arquitectura edge â†” cloud: On-premise (Confluent en GDC Edge) = Cloud (Confluent managed GKE)
   - Partner de GCP: FacturaciÃ³n en cuenta GCP via Marketplace
   - Desplegable en GKE Edge y GKE cloud con misma API

### Â¿Por quÃ© no MirrorMaker 2?

- RPO/RTO=0 requiere latencias sub-segundo
- Cluster Linking ofrece mejor rendimiento y simplicidad operacional

### Â¿Por quÃ© no ETL tradicional o multi-regiÃ³n estÃ¡ndar?

- ImplementaciÃ³n simple basada en eventos
- Carga operativa manejada por Confluent + GCP
- No requiere programaciÃ³n custom de resiliencia/recuperaciÃ³n

### Â¿Por quÃ© Google Distributed Cloud Edge + Stack 100% GCP Nativo?

**DecisiÃ³n arquitectÃ³nica**: GDC Edge (on-premise) + GKE (cloud) + Anthos unificado

**Razones clave**:

1. **Resiliencia Industrial Real (Offline-Capable)**:
   - GDC Edge permite operaciÃ³n local **sin dependencia de cloud**
   - Plantas pueden continuar operando durante cortes de conectividad
   - RPO/RTO â‰ˆ 0 local, procesamiento crÃ­tico no depende de latencia cloud
   - Ideal para entornos industriales con requisitos de disponibilidad extremos

2. **Stack 100% GCP Nativo (Un Solo Proveedor)**:
   - Google Distributed Cloud Edge + GKE + Anthos (ecosistema unificado)
   - Menor complejidad operativa: un solo vendor, un solo contrato
   - FinOps unificado: todo facturado en cuenta GCP Marketplace
   - Menor brecha de skills: mismo stack edge + cloud (Kubernetes/Anthos)

3. **Zero-Trust Nativo (IAP + Identity Platform)**:
   - Identity-Aware Proxy para accesos humanos sin VPN tradicional
   - FederaciÃ³n SAML/OIDC con AD corporativo/SSO nativa
   - Anthos Service Mesh con mTLS automÃ¡tico para todo el trÃ¡fico
   - Sin necesidad de soluciones de terceros (menor costo, menor complejidad)

4. **Conectividad Privada (PSC + Interconnect)**:
   - Private Service Connect (PSC) para conectividad edge â†” cloud privada
   - Sin overlaps de IPs entre plantas y cloud
   - Sin exponer IPs pÃºblicas, comunicaciÃ³n 100% privada
   - Interconnect 1Gbps + Cloud VPN HA como respaldo redundante

5. **Procesamiento Edge-First EstratÃ©gico**:
   - Procesar **localmente lo mÃ¡ximo posible y razonable** en planta
   - Pre-procesamiento, filtrado, priorizaciÃ³n en edge (KSQL)
   - Reducir volumen de datos hacia cloud (solo crÃ­ticos/agregados)
   - Cloud para mÃ©tricas multi-planta, analÃ­tica global, ML/AI
   - Datos sensibles permanecen on-prem (cumplimiento, privacidad)

6. **ReplicaciÃ³n AsÃ­ncrona Priorizada**:
   - **Alta prioridad**: Alarmas/telemetrÃ­a (Pub/Sub Lite â†’ Pub/Sub)
   - **Media prioridad**: Batch/analÃ­tica (Dataflow programado)
   - **Baja prioridad**: Logs/histÃ³ricos (Storage Transfer nocturno)
   - Optimiza uso de Interconnect 1Gbps con trÃ¡fico inteligente

7. **GestiÃ³n Unificada (Anthos Config Management)**:
   - GitOps Ãºnico para GDC Edge + GKE cloud
   - Anthos Config Management: despliegues declarativos centralizados
   - Policy Controller (OPA integrado): gobierno unificado
   - Un solo control plane para toda la infraestructura

8. **Costos Optimizados y Predecibles**:
   - Sin licencias de terceros (todo incluido en GCP)
   - FacturaciÃ³n consolidada GCP Marketplace (Confluent, Dataproc)
   - Cast.ai optimiza dinÃ¡micamente GKE + Dataproc (~40% ahorro)
   - Modelo OPEX predictible, sin sorpresas de mÃºltiples vendors

9. **Observabilidad Nativa Unificada**:
   - Cloud Operations Suite: mÃ©tricas, logs, traces edge + cloud
   - Anthos Service Mesh observability: latencias L7 automÃ¡ticas
   - OpenTelemetry: instrumentaciÃ³n estÃ¡ndar
   - Visibilidad end-to-end sin herramientas dispersas

**Trade-offs aceptados**:
- Dependencia de un solo proveedor (GCP) vs estrategia multi-cloud
- Requiere Interconnect funcional (âœ… ya operativo segÃºn caso de negocio pÃ¡g. 4)
- Menor flexibilidad para futuro multi-cloud (mitigado: Kubernetes/Anthos portabilidad)

### Â¿Por quÃ© Harness?

- Internal Developer Portal (Backstage)
- Control completo del ciclo de vida
- Blue/Green y Canary nativo
- Chaos Engineering para RPO/RTO
- MÃ©tricas DORA y SPACE
- FinOps predictivo integrado
- OPA para polÃ­ticas

### Â¿Por quÃ© Cast.ai?

- ReducciÃ³n hasta 40% en costos de compute (GKE + GDC Edge)
- GestiÃ³n dinÃ¡mica predictiva inteligente de recursos K8s
- OptimizaciÃ³n automÃ¡tica de nodos, right-sizing pods
- Compatible con GKE cloud y GKE Edge (mismo runtime Kubernetes)
- LLM/Data caching para reducir latencia y costos transferencia
- Alternativa vs autoscaling nativo GKE (mÃ¡s agresivo en ahorro)

### Â¿Por quÃ© Dataproc on GKE vs Databricks?

**DecisiÃ³n**: Usar **Dataproc on GKE** (edge + cloud) en lugar de Databricks

**Razones clave**:

1. **Despliegue Edge + Cloud Unificado**:
   - Dataproc on GKE funciona tanto en GKE cloud como en GKE Edge (on-premise)
   - Databricks no soporta despliegue on-premise nativo en GKE Edge
   - Arquitectura homogÃ©nea: mismo stack Spark en plantas y cloud

2. **OptimizaciÃ³n Cast.ai**:
   - Dataproc on GKE permite que Cast.ai optimice dinÃ¡micamente los workers K8s (~40% ahorro)
   - Databricks tiene autoscaling propio, pero sin integraciÃ³n Cast.ai
   - GestiÃ³n unificada de recursos K8s (GKE + Dataproc) en un solo plano

3. **FinOps Unificado**:
   - Dataproc facturado en cuenta GCP Marketplace (consolidado)
   - Databricks requiere contrato/facturaciÃ³n separada (multiproveedor)
   - Menor complejidad TCO: todo en una factura GCP

4. **Costos Menores**:
   - Dataproc on GKE: Pago por uso Spark managed + compute GKE
   - Databricks: Premium sobre Spark + markup significativo (~2-3Ã— sobre Dataproc)
   - Para workloads batch/streaming estÃ¡ndar, Dataproc suficiente

5. **GestiÃ³n Anthos Unificada**:
   - Dataproc on GKE gestionado via Anthos Config Management
   - GitOps unificado para toda la plataforma (edge + cloud)
   - Databricks requiere plane de control separado

**Trade-off aceptado**:
- Databricks tiene mejor UX para Data Scientists (notebooks colaborativos, Delta Lake optimizado)
- MitigaciÃ³n: Vertex AI Workbench + BigQuery para analÃ­tica colaborativa
- Para procesamiento streaming/batch industrial, Dataproc on GKE suficiente

**CuÃ¡ndo considerar Databricks** (futuro):
- Si se requiere Delta Lake con optimizaciones avanzadas (ZORDER, OPTIMIZE, etc.)
- Si equipos de DS necesitan notebooks colaborativos avanzados (no cubierto por Vertex AI Workbench)
- Si se migra a ML/AI intensivo que justifique el costo premium

## Modelo de Gobierno

### PolÃ­ticas OPA

1. **Presupuestos y Cuotas** (definir desde dÃ­a 1):
   - VMs, disco, memoria
   - Logs, mÃ©tricas
   - LLM tokens/llamadas
   - Egreso de red

2. **Aprobaciones explÃ­citas**: Equipos deben pedir exceder cuotas

3. **ValidaciÃ³n pre-despliegue**: OPA valida recursos antes de cualquier deploy

4. **Gobernanza Harness**: Control centralizado de polÃ­ticas

### EstÃ¡ndares de Eventos

**Principio fundamental**: TODO se debe escribir como eventos en tÃ³picos RAW

1. **Definir estÃ¡ndar de evento** desde el inicio
2. **No pensar si se compartirÃ¡**: Escribir todo
3. **Responsabilidad del consumidor**: Filtrar y transformar segÃºn necesidad
4. **Habilita arquitectura evolutiva**: MigraciÃ³n gradual sin romper flujos
5. **Change Data Capture**: Convertir legados a eventos para mantener o migrar sin impacto

### FinOps

#### KPIs Objetivo
- Forecast accuracy â‰¥ 90% mensual
- Cobertura CUD/RI â‰¥ 60% a 12 meses
- Right-sizing ratio â‰¥ 20% primeros 90 dÃ­as
- Idle/Orphan rate < 3%
- Label compliance â‰¥ 95%
- Variance vs presupuesto â‰¤ Â±5%
- Costo unitario: USD/unidad producida

#### MVP IA para FinOps
- **Forecast**: DescomposiciÃ³n estacional/regresiÃ³n por proyecto/BU/onda
- **AnomalÃ­as**: Reglas + umbrales dinÃ¡micos (Â±2Ïƒ o +8% sobre forecast)
- **NLP Etiquetado**: Inferir owner/cost_center/criticality en gastos huÃ©rfanos

#### FacturaciÃ³n Consolidada GCP
- Confluent: Via GCP Marketplace (orden de compra)
- Grafana: Via GCP Marketplace (orden de compra)
- ConversaciÃ³n con Account Managers de GCP
- Soluciona "problema" de tecnologÃ­as fuera de GCP

## Estructura de Equipos

### Roles Especializados

1. **Arquitecto de Plataforma**: DiseÃ±o arquitectura distribuida, Kafka Confluent, Anthos, GDC Edge, Dataproc on GKE
2. **Arquitecto de Datos**: Data hub, capas medallion, lakehouse, BigQuery, edge â†” cloud sync, Dataproc
3. **Administradores Sistemas Legados/On-Premise**: IntegraciÃ³n SCADA, SQL Server, GDC Edge deployment
4. **Experto en Redes**: Private Service Connect, Interconnect, VPN HA, Anthos Service Mesh
5. **DevSecOps**: GitOps con Anthos Config Management, Harness, Policy Controller, IAP
6. **Data Engineer**: Pipelines KSQL edge, Dataproc on GKE cloud, Kafka Connect, Debezium, priorizaciÃ³n
7. **Data Scientist**: MLOps, Vertex.ai, FinOps LLM, modelos forecast/anomalÃ­as, Dataproc notebooks
8. **Finanzas**: TCO, CAPEX/OPEX, CUD/RI, unit economics, sensibilidades, FinOps unificado GCP

### MetodologÃ­a de Trabajo

1. **ColaboraciÃ³n en ciclos**: Cada tarea requiere discusiÃ³n y retroalimentaciÃ³n del equipo
2. **ValidaciÃ³n cruzada**: Un rol revisa y cuestiona decisiones de otros
3. **Decisiones consensuadas**: Trade-offs se discuten entre todos los roles
4. **PresentaciÃ³n al CEO**: Equipo completo participa

## Entregables del Proyecto

### 1. Memo Ejecutivo (2-3 pÃ¡gs)
- DecisiÃ³n recomendada (regiones, patrÃ³n DR, edge OT)
- Decisiones C-level requeridas
- CAPEX/OPEX por ondas y payback
- Sensibilidades (Â±10-20%)
- Riesgos top-5 y trade-offs

### 2. Caso de Negocio (10-15 pÃ¡gs)
- Principios de arquitectura
- Modelo financiero 3 aÃ±os
- FinOps y gobierno de costos
- Modelo operativo y liderazgo (RACI)
- GestiÃ³n del cambio

### 3. MVP de IA para FinOps
- Forecast de costos
- DetecciÃ³n de anomalÃ­as
- NLP de etiquetado
- Dataset provisto en caso de negocio

### 4. Plan Maestro (Gantt, 12-18 meses)
- Fases, hitos Go/No-Go
- Rollback procedures
- Dependencias con ventanas y freeze

### 5. Deck Ejecutivo (5-8 slides)
- Para CIO/CTO/CFO/CEO
- SituaciÃ³n, propuesta, roadmap, TCO/ROI
- Riesgos y prÃ³ximos pasos

### 6. Diagramas Mermaid
- Arquitectura de alto nivel
- Flujo de datos (data hub)
- TopologÃ­a de red
- GitOps workflow
- FinOps governance

## Fases del Proyecto (Plantilla Gantt)

| ID | Fase | Inicio | Fin | DuraciÃ³n | Dependencias | Hito |
|----|------|--------|-----|----------|--------------|------|
| 1 | MovilizaciÃ³n & CCoE | 2025-11-24 | 2026-01-31 | 69 dÃ­as | â€” | Charter aprobado |
| 2 | Conectividad & Seguridad | 2025-12-02 | 2026-02-28 | 89 dÃ­as | 1 | SEG listo |
| 3 | Datos â€“ OLA/CDC | 2026-01-05 | 2026-04-30 | 116 dÃ­as | 1-2 | DQ â‰¥ 98% |
| 4 | Piloto (10-15 apps) | 2026-02-10 | 2026-05-31 | 111 dÃ­as | 1-3 | Piloto OK |
| 5 | Onda 1 (â‰ˆ30%) | 2026-04-15 | 2026-08-31 | 139 dÃ­as | 4 | Go-Live O1 |
| 6 | Onda 2 (â‰ˆ60%) | 2026-07-01 | 2026-12-20 | 173 dÃ­as | 5 | Go-Live O2 |
| 7 | CrÃ­ticos (â‰ˆ10%) | 2026-10-01 | 2027-02-28 | 151 dÃ­as | 6 | Go-Live crÃ­ticos |
| 8 | Cierre & OptimizaciÃ³n | 2027-01-05 | 2027-03-31 | 85 dÃ­as | 7 | BAU |

## Escenarios de Liderazgo

### Escenario 1: Sobre-ejecuciÃ³n Q2 (+15% vs presupuesto)
- Ajuste CUD/RI
- Right-sizing
- Lifecycle storage
- Apagar entornos no-prod
- Re-faseo de ondas
- ComunicaciÃ³n CFO/BU

### Escenario 2: DegradaciÃ³n OT por latencia
- Activar operaciÃ³n local-first (edge)
- Protocolo de roll-back
- CoordinaciÃ³n con Operaciones
- Plan de remediaciÃ³n

### Escenario 3: Cambio de prioridades del negocio
- Adelantar Analytics/IoT
- No romper RPO/RTO de crÃ­ticos
- Mantener variance â‰¤ Â±5%
- Explicar decisiones y trade-offs

## Matriz de Riesgos (MÃ­nimo 12)

1. Latencia OT/SCADA (mitigado con GDC Edge local-first)
2. Viabilidad RPO/RTO=0 inter-regiÃ³n edge â†” cloud
3. .exe locales en procedimientos almacenados
4. Brecha de skills GCP/Anthos/FinOps
5. Ventanas de planta/freeze
6. Etiquetado/Reserved Instances/CUD
7. Seguridad/compliance
8. Licenciamiento GCP Distributed Cloud Edge
9. Cortes de energÃ­a en Monterrey (mitigado con operaciÃ³n offline-capable)
10. Dependencias ocultas
11. Shadow-IT
12. Dependencia de un solo proveedor (GCP) vs multi-cloud
13. AdopciÃ³n Anthos Config Management por equipos on-prem
14. Interconnect como punto Ãºnico de falla (mitigado con VPN HA)

## Supuestos Clave

1. **GDC Edge disponibilidad**: Google Distributed Cloud Edge estÃ¡ disponible en MÃ©xico/plantas (validar con GCP Account Team)
2. **Confluent en GKE Edge**: Confluent Kafka desplegable en GKE Edge con mismo desempeÃ±o que GKE cloud
3. **Dataproc on GKE Edge**: Dataproc soporta despliegue en GKE Edge para procesamiento local (validar con GCP)
4. **FacturaciÃ³n GCP consolidada**: Confluent + Dataproc facturados via GCP Marketplace (confirmado partner GCP)
5. **Skills internos**: Se requiere upskilling significativo en Anthos, Kafka, Dataproc, Kubernetes, FinOps
6. **Conectores propietarios**: Proveedores de SCADA pueden tener conectores para enviar CDC a Kafka (investigar)
7. **Dataproc Personal Cluster**: Viabilidad de replicar arquitectura Dataproc en laptops para dev/test local
8. **Cast.ai savings**: 40% de reducciÃ³n es alcanzable segÃºn benchmarks (aplicable a GKE + Dataproc workers)
9. **Policy Controller enforcement**: Todas las polÃ­ticas OPA pueden ser enforzadas pre-despliegue via Anthos
10. **Interconnect capacidad**: 1Gbps suficiente para workloads edge â†’ cloud priorizados, requiere monitoreo
11. **Change Data Capture**: Todos los sistemas legacy soportan CDC via Kafka Connect/Debezium
12. **OperaciÃ³n offline edge**: GDC Edge + Dataproc pueden operar 100% offline sin conectividad cloud durante cortes
13. **PSC latencia**: Private Service Connect no aÃ±ade latencia significativa vs Interconnect directo (<1ms overhead)
14. **Anthos licensing**: Costos de licenciamiento Anthos para edge + cloud son viables vs VMware/Cloudflare eliminados
15. **Dataproc vs Databricks**: Para workloads batch/streaming estÃ¡ndar industriales, Dataproc on GKE suficiente (no requiere Databricks premium)

## TecnologÃ­as Complementarias

### Entorno de Desarrollo Local
- **Redpanda**: Kafka-compatible ligero para laptops (simula Confluent local)
- **Dataproc Personal Cluster**: Cluster Dataproc mÃ­nimo para desarrollo/testing local
- **Kind (Kubernetes in Docker)**: Simula GKE Edge/cloud localmente
- **Skaffold**: Desarrollo local con hot-reload para GKE + Dataproc
- **Config Sync (local mode)**: Prueba GitOps Anthos localmente
- **Docker Compose**: OrquestaciÃ³n bÃ¡sica para pruebas rÃ¡pidas (Kafka + Spark standalone mÃ­nimo)
- **RazÃ³n**: Dataproc Personal Cluster permite probar jobs Spark localmente con API idÃ©ntica a producciÃ³n

### Conectores Kafka
- **Debezium**: CDC para SQL Server, PostgreSQL, MySQL, MongoDB, etc.
- **JDBC Source/Sink**: Conectividad BD genÃ©rica
- **Investigar**: Conectores propietarios SCADA (OPC-UA, Modbus, etc.)

## Nomenclatura de Entrega

- `Memo_Ejecutivo_LiderCloudFinOps_<Apellido>.pdf`
- `Caso_Negocio_LiderCloudFinOps_<Apellido>.pdf`
- `MVP_IA_FinOps_<Apellido>.pdf`
- `Plan_Gantt_<Apellido>.xlsx` o `.md`
- `Deck_Ejecutivo_<Apellido>.pdf`

## Referencias TÃ©cnicas

### Precios Base GCP (Price Pack)
- Compute on-demand: USD 24/vCPU-mes, USD 3/GB-RAM-mes
- SQL administrado: 1.6Ã— costo compute equivalente
- Block storage: 0.12/GB-mes
- Object Standard: 0.023/GB-mes
- Snapshots: 0.05/GB-mes
- Interconnect: USD 3,000/mes (2 puertos)
- Egress Internet: 0.05/GB (primeros 30 TB/mes)
- Soporte GCP: USD 12,500/mes
- OperaciÃ³n Cloud (equipo base): USD 75,000/mes
- One-time: USD 1,700,000

### Inventario de Cargas
| CategorÃ­a | Monterrey | Guadalajara | Tijuana | Total |
|-----------|-----------|-------------|---------|-------|
| SCADA modernos | 10 | 10 | 10 | 30 |
| SCADA antiguos (crÃ­ticos) | 10 | 10 | 20 | 40 |
| SQL Server 2008-2012 (Plantas) | 10 | 10 | 20 | 40 |
| SQL Server 2019 (Plantas, crÃ­ticos) | 10 | 10 | 20 | 40 |
| SQL Server 2008-2012 (Corp.) | 20 | 20 | 20 | 60 |
| SQL Server 2019 (Corp., crÃ­ticos) | 20 | 20 | 40 | 80 |
| Aplicaciones IIS (Plantas) | 20 | 20 | 20 | 60 |
| Aplicaciones IIS (Corp.) | 30 | 0 | 0 | 30 |
| **Total** | **130** | **100** | **150** | **380** |

### ProducciÃ³n por Planta
| Planta | ProducciÃ³n mensual | ProducciÃ³n anual |
|--------|-------------------|------------------|
| Monterrey | 60,000 unid. | 720,000 unid. |
| Guadalajara | 40,000 unid. | 480,000 unid. |
| Tijuana | 30,000 unid. | 360,000 unid. |
| **Total** | **130,000 unid.** | **1,560,000 unid.** |

## PrÃ³ximos Pasos

1. **Kickoff con sub-agentes**: Cada rol especializado analiza el caso desde su perspectiva
2. **Sesiones de diseÃ±o colaborativo**: DiscusiÃ³n y retroalimentaciÃ³n cruzada
3. **GeneraciÃ³n de artefactos**: DocumentaciÃ³n, diagramas Mermaid, modelos financieros
4. **RevisiÃ³n y refinamiento**: IteraciÃ³n basada en feedback del equipo
5. **ConsolidaciÃ³n final**: GeneraciÃ³n de PDFs para entrega

---

**VersiÃ³n**: 1.0
**Fecha**: 2025-10-31
**Autor**: Equipo de Arquitectura Cloud & FinOps
